---
title: 并行分布式概念
date: 2021-01-12 09:17
tags:
- 并行分布式
---
# 概述
# 1.分布和并行的区别：
+ 并行：是在同一台机器上的，机器是多核处理器的，可以把问题并行化进行编程
+ 分布：多台机器之间，使用网络连接的方式，构成一个整体，对外以整体提供服务

# 2.并行和并发的区别：
+ 并行：系统支持两个任务同时执行。比如边吃饭边打电话
+ 并发：系统支持两个任务同时存在，具有处理多个任务的能力，不一定要同时处理。比如吃饭吃到一半，停下来打电话，打完电话之后继续吃饭。
并行是并发的一个子集

# 3.进程和线程的区别：
+ 进程：资源分配的最小单位。系统中正在运行的应用程序就是一个进程。每个进程都有独立的代码和数据空间。
+ 线程： CPU调度的最小单位。同一类线程共享代码和数据控件，每个线程都有自己独立的运行栈和程序计数器。
操作系统可以同时运行多个进程，一个进程中可以同时执行多个线程。

# 4.并发编程中的两种观点
1. 消息传递（Message-Passing）编程。没有任何共享状态，所有同步和通信都是通过交换消息完成的。
2. 分布式内存（distributed-memory）编程。通过读取/写入共享内存块进行通信，共享内存块受信号量/锁等的保护。

# 5. 并行计算的核心
并行计算的核心是指计算机能够以任何顺序来执行的独立计算。
并行计算需要考虑以下几点：
1. 把并发工作分配到多个线程上，需要调用一些实现了线程化机制的库函数，这些函数将增加开销。 （java的thread类，run方法，线程池等方法）
2. 存储冲突或数据竞争 （多线程要访问/修改的相同变量可能需要使用信号量/锁等来保护）
3. 线程同步 （当有一个线程在对内存进行操作的时候，其他线程都不可以对这个内存地址进行操作。）

# 6. 并行编程的步骤
1. 寻找并发性 （数据/任务划分）
2. 算法结构 
3. 支持结构
4. 实现机制

# 7.基于线程化方法学
1. 分析
2. 设计与实现
3. 测试正确性
4. 性能优化

***
# 并行硬件和并行软件
# 1. 基于Flynn分类法的划分
Flynn分类法，是基于指令流和数据流的数量对计算机进行分类的方法。
1. 单指令单数据流（single instruction single data stream）SISD:SISD机器是一种传统的串行计算机，不支持任何并行计算。在某个时钟周期内，CPU只能处理一个数据流
2. 单指令多数据流（single instruction multiple data stream）SIMD： 对多个数据执行相同的指令从而实现在多个数据流上的操作。可以实现数据的并行性。例如同时执行1 + 1和2 + 2
- 缺点： 
    1. 全部ALUs必须执行相同指令或者等待
    2. 在经典的设计中，他们也必须同步操作
    3. ALUs没有指令存储。
    4. 适用于大型数据并行问题上，处理其他并行 问题并不优秀
- SIMD运用的领域： 
    1. 向量处理系统。可以对不同的数据并行执行相同的操作
    2. （图像处理）GPUS的着色函数的功能是隐式并行的，他们可以被应用到图形流的多个元素，GPU可以使用SIMD并行来优化算法，*不是纯粹的SIMD系统*。

3. 多指令流单数据流（multiple instruction single data stream）MISD： 比较少见，这种冗余多用于容错系统。
4. 多指令多数据流（multiple instruction multiple data stream）MIMD： 类似于多个SISD系统，常见的例子是多处理器计算机。

# 2. MIMD的进一步划分
1. MIMD的基本架构
![](1.png)
2. MIMD的分类
    1. 共享内存 
    ![](2.png)  
>    定义：
    一组自治的处理器通过互联网络与内存系统
    相连接，每个处理器能访问每个内存区域
    每个处理器都可以访问每个存储单元
    处理器通过访问共享的数据结构来隐式通信  

    2. UMA多核系统
    ![](3.png)  
>   每个核访问内存中的任何一个区域的时间相同  

    3. 分布式内存
    ![](4.png)
>   集群
        商品化系统组成
        通过商品化网络互连  
        节点 通过网络互联的独立计算单元


# 3.度量
>   Tparallel是并行运行时间  
    Tserial是串行运行时间   
    p是处理器的核心数目  
    S是加速比
公式： 
1. 加速比
```math
T_{parallel} = T_{serial} /p
```

```math
S=T_{serial} / T_{parallel}
```

2. 效率

```math
E=S/p={(T_{serial} / T_{parallel})}/p

```


3. 并行开销
```math
T_{parallel}=T_{serial}/p+T_{overhead}

```

*** 
# 寻找并发性设计空间
# 1. 并行编程的第一个步骤寻找并发性的进一步划分：
1. 分解： 任务分解和数据分解
2. 依赖分析： 任务分组，任务排序，数据共存
3. 设计评估

# 2. 任务分解
计算被分解为一组独立的任务，多个线程可以用任意顺序执行这些任务  

例子. 以园艺工作举例，任务分解会建议园丁按工作本身的属性分配任务：如果两个园丁到达一个客户家，一个修剪草坪，另一个铲除杂草。修剪草坪和铲除杂草是两个被分开的功能
# 3. 数据分解
应用程序需要处理一个大型数据集，并且可以对数据集中的每个元素进行独计算  
例子. 如果园丁应用数据分解来分解他们的任务，他们两个会同时修剪一半的草坪，然后两个人分别铲除一半的杂草

***
# 4. 算法结构
- 评价
  1. 效率
  2. 简单性
  3. 可移植性
  4. 可扩展性
- 注意
  1. 效率与可移植性冲突
  2. 效率与简单性冲突
- 算法结构决策树
![](5.png)

1. 任务并行模式
定义：把问题分解为一个能够并发执行的任务集合,高效的挖掘这种并发性
任务并行的三个元素：
    1. 任务和他们的定义方式
    2. 任务间的依赖性
    3. 调度（任务怎样分配到UE）
例子. 类似于任务分解，园丁
2. 分治策略：
问题被划分为许多较小的子问题，独立求解每一个子问题，并将所有的子问题解决方案合并为整个问题的解决方案，而求解整个问题
+ 特点：任务的递归安排
3. 几何分解模式：
围绕着一个已经分解为多个同时可更新的“块”的数据结构的算法模式
类似于数据分解
4. 流水线模式：
CPU指令流水
5. 基于事件的协作模式：
一些问题可以非常自然的表示为一个关于半独立实体的集合，这些半独立实体
以一种不规则的方式交互

# 5. 支持结构
1. 程序结构
## 1. SPMD（单程序多数据）
+ 在SPMD程序中，所有UE并行执行同一个程序（单程序），但每个UE都拥有自己的私有数据集（多数据）
## 2. 主从模式
- 定义：主进程为从进程建立一个工作池和一个任务包。所有从进程并发执行，每个从进程迭代的从任务包中移除一个任务并处理它，直到所有任务都处理完毕或到达某些终止条件为止。
- 实现方法：
（平时实验使用的方法）
1. 主线程中new新的子线程
2. 使用线程池
## 3. 派生/聚合
一个主UE派生出多个子UE，这些子UE并行完成全部工作的某一部分。通常派生UE处于等待状态，指导所有子UE完成任务和执行聚合操作。**和主从模式的区别在于：派生聚合下，当前代的子任务无需完全做完才开始迭代下一代，根据子任务的完成进度可以不断派生。**
2. 数据结构模式
> 1. 共享数据
定义抽象数据类型，实现一种合理的并发控制协议，一次执行一个操作
> 2. 共享队列
使用“线程安全”实现，即使并发执行的多个UE共同使用时，该实现也能保证正确。
RocketMQ，生产者消费者模型实验
> 3. 分布式数组
一维或多维数组，被划分为多个子数组，并在进程或线程间进行分配

***
# 6.机制设计空间
1. UE管理
创建、销毁和管理并行计算中使用的进程与线程
2. 同步
对不同UE中的事件强制约定某种顺序，确保当UE集合访问共享资源时，不论如何调度UE，程序都能正确执行

3. 通信
在UE之间交换信息
## 1. 消息传递
**消息传输是双边的**(socket)
## 2. 集合通信
两个以上UE参与通信事件时，该事件称为集合通信操作:
- 广播：发送单条消息给所有UE
- 栅栏：程序中的同步点，所有UE都必须到达该点，然后才能继续向后执行
- 归约：获得一个对象集合，每个对象映射到一个UE，操作把它们组合为位于一个UE的单个对象，或组合它们并将结果广播到每个UE上
## 3. 其他通信构造
